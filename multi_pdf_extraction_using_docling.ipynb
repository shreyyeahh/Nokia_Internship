{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyyeahh/Nokia_Internship/blob/main/multi_pdf_extraction_using_docling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MNuNTT71y-uG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "196f2cda-3ccb-4afc-8c59-2f0ca7d3d5c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ufok0MrRzL4X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "import textwrap\n",
        "import torch\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NYkQofHW0nnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b350428b-5114-405a-d384-ff1b69b6e0d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API Key set successfully.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import userdata\n",
        "    # Set the OpenAI API key from Colab Secrets\n",
        "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "    print(\"OpenAI API Key set successfully.\")\n",
        "except (ImportError, KeyError):\n",
        "    print(\"Warning: Could not find 'OPENAI_API_KEY' in Colab Secrets.\")\n",
        "    print(\"Please set it manually or the function will fail.\")\n",
        "    # For local development, you might set it directly, but this is not recommended for notebooks:\n",
        "    # os.environ['OPENAI_API_KEY'] = \"YOUR_SK-...\"\n",
        "\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fhRGtJQ0z1YL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#! pip install -U ipywidgets\n",
        "! pip install docling\n",
        "! pip install pdf2image\n",
        "! apt-get update && apt-get install -y poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jP9Yfvxvz5bw"
      },
      "outputs": [],
      "source": [
        "# Visualization and PDF/Image handling\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from pdf2image import convert_from_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VBIzpYqcz9-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4b95ada-7215-40e1-84c6-16771c7f4747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Transformers in /usr/local/lib/python3.11/dist-packages (4.54.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from Transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from Transformers) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from Transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from Transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from Transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from Transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from Transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from Transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from Transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from Transformers) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->Transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->Transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->Transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->Transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->Transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->Transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->Transformers) (2025.7.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install Transformers scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ignAd5L1z_Fs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d1fc9f-95ae-4f9c-e46b-08c468ed6b24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.54.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (0.34.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.7.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "F0pj900i0D3O"
      },
      "outputs": [],
      "source": [
        "from docling.datamodel.base_models import InputFormat\n",
        "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
        "from docling.datamodel.pipeline_options import PdfPipelineOptions, TableFormerMode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rwJj7GME0HTS"
      },
      "outputs": [],
      "source": [
        "# Sentence-Transformers for semantic embeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tmx0mSY61csr"
      },
      "outputs": [],
      "source": [
        "def extract_content_from_single_pdf(input_data_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Extracts content from a single PDF using Docling.\n",
        "    If tables are found, it processes them.\n",
        "    If no tables are found, it treats the entire document text as a single block.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        pipeline_options = PdfPipelineOptions(do_table_structure=True)\n",
        "        pipeline_options.table_structure_options.mode = TableFormerMode.ACCURATE\n",
        "        doc_converter = DocumentConverter(\n",
        "            allowed_formats=[InputFormat.PDF],\n",
        "            format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)}\n",
        "        )\n",
        "        result = doc_converter.convert(input_data_path)\n",
        "\n",
        "        all_content_blocks = []\n",
        "\n",
        "        if not result.document.tables:\n",
        "            all_content_blocks.append({\n",
        "                \"original_table_number\": 1,\n",
        "                \"table_content\": result.document.text\n",
        "            })\n",
        "        else:\n",
        "            for table_ix, table in enumerate(result.document.tables):\n",
        "                table_df = table.export_to_dataframe()\n",
        "                table_content_string = table_df.to_string()\n",
        "                all_content_blocks.append({\n",
        "                    \"original_table_number\": table_ix + 1,\n",
        "                    \"table_content\": table_content_string\n",
        "                })\n",
        "\n",
        "        return pd.DataFrame(all_content_blocks)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  - Error processing file {Path(input_data_path).name}: {e}\")\n",
        "        return pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "08oaQVXe1jJr"
      },
      "outputs": [],
      "source": [
        "def process_pdf_database(directory_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Processes all PDFs in a given directory to create a final DataFrame of extracted content.\n",
        "    \"\"\"\n",
        "    pdf_files = list(Path(directory_path).glob('*.pdf'))\n",
        "    if not pdf_files:\n",
        "        print(f\"No PDF files found in directory: {directory_path}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    all_pdfs_data = []\n",
        "\n",
        "    print(f\"Found {len(pdf_files)} PDFs. Starting processing...\")\n",
        "\n",
        "    for pdf_path in tqdm(pdf_files, desc=\"Processing PDFs\"):\n",
        "        pdf_name = pdf_path.name\n",
        "        extracted_df = extract_content_from_single_pdf(str(pdf_path))\n",
        "\n",
        "        if not extracted_df.empty:\n",
        "            extracted_df['pdf_name'] = pdf_name\n",
        "            all_pdfs_data.append(extracted_df)\n",
        "\n",
        "    if not all_pdfs_data:\n",
        "        print(\"Processing complete, but no data was successfully extracted from any PDF.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    master_df = pd.concat(all_pdfs_data, ignore_index=True)\n",
        "    final_columns = ['pdf_name', 'original_table_number', 'table_content']\n",
        "    master_df = master_df[final_columns]\n",
        "\n",
        "    return master_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "r8ul-tNT1zXh"
      },
      "outputs": [],
      "source": [
        "def create_embeddings(df: pd.DataFrame, model_name: str = 'all-MiniLM-L6-v2'):\n",
        "    \"\"\"\n",
        "    Creates semantic embeddings for the text chunks using a sentence-transformer model.\n",
        "    \"\"\"\n",
        "    print(f\"Loading sentence-transformer model: {model_name}...\")\n",
        "    model = SentenceTransformer(model_name)\n",
        "    print(\"Model loaded. Generating embeddings for all content blocks...\")\n",
        "\n",
        "    corpus = df['table_content'].tolist()\n",
        "    embeddings = model.encode(corpus, show_progress_bar=True, convert_to_tensor=True)\n",
        "\n",
        "    print(\"Embeddings generated successfully.\")\n",
        "    return model, embeddings.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lPHfGmjl2DUV"
      },
      "outputs": [],
      "source": [
        "def search_documents_semantic(query: str, model, embeddings, original_df: pd.DataFrame, top_n: int = 10) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Searches the documents using semantic embeddings and returns the most relevant content blocks.\n",
        "    \"\"\"\n",
        "    query_embedding = model.encode([query], convert_to_tensor=True)\n",
        "    cosine_sims = cosine_similarity(query_embedding.cpu().numpy(), embeddings).flatten()\n",
        "\n",
        "    if len(cosine_sims) > top_n:\n",
        "        top_indices = np.argpartition(-cosine_sims, top_n)[:top_n]\n",
        "        sorted_top_indices = top_indices[np.argsort(-cosine_sims[top_indices])]\n",
        "    else:\n",
        "        sorted_top_indices = np.argsort(-cosine_sims)\n",
        "\n",
        "    results = original_df.iloc[sorted_top_indices].copy()\n",
        "    results['similarity_score'] = cosine_sims[sorted_top_indices]\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "23Bc4Ca42G7C"
      },
      "outputs": [],
      "source": [
        "def generate_final_answer(query:str,retrieved_chunks_df:pd.DataFrame)->str:\n",
        "   \"\"\"\n",
        "    Uses OpenAI's gpt-4o-mini model to generate a final answer from retrieved chunks.\n",
        "    \"\"\"\n",
        "   try:\n",
        "      client = openai.OpenAI()\n",
        "   except openai.AuthenticationError:\n",
        "      return \"OpenAI key not set or invalid\"\n",
        "\n",
        "   #step 1 - combine the raw chunk content into single context string\n",
        "   context = \"\\n---\\n\".join(retrieved_chunks_df['table_content'])\n",
        "\n",
        "    # --- LLM CALL 1: Summarize/Clean the context ---\n",
        "   summarization_prompt = f\"\"\"\n",
        "   Based on the following raw data chunks, synthesize the key information into a clear, factual paragraph.\n",
        "   Focus on accurately extracting facts, figures, and specifications.\n",
        "   Do not add any information that is not present in the text.\n",
        "     Raw data:\n",
        "    ---\n",
        "    {context}\n",
        "    ---\n",
        "    Clean Summary:\n",
        "    \"\"\"\n",
        "\n",
        "   print(\"\\n--- Step 4a: Generating Clean Context (with gpt-4o-mini)... ---\")\n",
        "   try:\n",
        "        summarization_response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an expert technical assistant that summarizes raw document data into clean, readable text.\"},\n",
        "                {\"role\": \"user\", \"content\": summarization_prompt}\n",
        "            ],\n",
        "            temperature=0.0 # Low temperature for factual summarization\n",
        "        )\n",
        "        clean_context = summarization_response.choices[0].message.content\n",
        "        print(textwrap.fill(clean_context, width=80))\n",
        "   except Exception as e:\n",
        "        print(f\"An error occurred during summarization: {e}\")\n",
        "        return \"Failed to generate a clean context from the retrieved documents.\"\n",
        "\n",
        "    # --- LLM CALL 2: Generate the final answer ---\n",
        "   answer_prompt = f\"\"\"\n",
        "    Using ONLY the context provided below, give a direct and comprehensive answer to the user's question.\n",
        "    Cite the source PDF for key pieces of information if available.\n",
        "    If the context does not contain the information needed to answer the question, state that the answer is not available in the provided documents.\n",
        "\n",
        "    Context:\n",
        "    ---\n",
        "    {clean_context}\n",
        "    ---\n",
        "    User's Question: {query}\n",
        "\n",
        "    Final Answer:\n",
        "    \"\"\"\n",
        "\n",
        "   print(\"\\n--- Step 4b: Generating Final Answer (with gpt-4o-mini)... ---\")\n",
        "   try:\n",
        "        answer_response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful question-answering assistant that strictly uses the provided context to answer questions.\"},\n",
        "                {\"role\": \"user\", \"content\": answer_prompt}\n",
        "            ],\n",
        "            temperature=0.2 # Slightly higher temp for more natural language\n",
        "        )\n",
        "        final_answer = answer_response.choices[0].message.content\n",
        "   except Exception as e:\n",
        "        print(f\"An error occurred during final answer generation: {e}\")\n",
        "        return \"Failed to generate a final answer.\"\n",
        "\n",
        "   return final_answer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_ZYcjrnK96zf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b28deba4070b4ae7b18c0a545f5d5b25",
            "8a99af8fbefd45099ac6735f1fb48b37",
            "e0c77736ba2c4eb5aff2afddfe950f6b",
            "a9baaa876a5c4ddb8453ae68f5f41f0f",
            "73d54e9ae76a4606a44806ea5ae44982",
            "bdc89286104e437c8ab0e921f70d6685",
            "b11342e0c3924078b5cdfef929217c9f",
            "9812d33e2fe842909415ea9dd4777848",
            "070e3f9def5c419eae6f879abb48e1a0",
            "f04180e5fce0466ab87199b60b7c9076",
            "f8d0e75209d74dfa87eee58048349425",
            "87da898d54cc4f36b8647b212a0c9cb1",
            "d23f9fe295824deea94b87c7a7652751",
            "80c3c48c43294a80bf2040bfa60caeb8",
            "c2f2b1206dbb41b2b8415688dd3a16de",
            "affbbcb1cd364002bff01b6e8686beb9",
            "9e7b7816233c4f9ebcf27d670db26e7b",
            "97cee9ab229d42aa85b01626df2e07ee",
            "51f7a867066f4bbdbefd9d0df4b1fa7c",
            "bc5b3c9d362b4f2fa46db800460f2ab5",
            "c8f9f0016834464596df37a6ade61951",
            "e39a85a4ab9a4b1186dfe626c2c4fd98"
          ]
        },
        "outputId": "3af3dbe7-40ac-45fe-d4ff-3d12f2e0cc26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Target directory set to: /content/drive/MyDrive/pdf_folder/\n",
            "Found 4 PDFs. Starting processing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing PDFs:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b28deba4070b4ae7b18c0a545f5d5b25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Successfully created a master DataFrame with 6 text chunks.\n",
            "\n",
            "Saved the master DataFrame to 'master_database.csv'\n",
            "Loading sentence-transformer model: all-MiniLM-L6-v2...\n",
            "Model loaded. Generating embeddings for all content blocks...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87da898d54cc4f36b8647b212a0c9cb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings generated successfully.\n",
            "Saved document embeddings to 'document_embeddings.npy'\n",
            "\n",
            "==================================================\n",
            "System is ready. You can now ask questions.\n",
            "==================================================\n",
            "Enter your semantic query (or type 'exit' to quit): What is the weight of the MTI MT-799012/W antenna?\n",
            "\n",
            "--- Step 4: Retrieving relevant chunks... ---\n",
            "Top Retrieved Chunks (for context):\n",
            "                                       pdf_name  original_table_number  \\\n",
            "4                                MT-799012W.pdf                      2   \n",
            "2                             ANT-SL-300-24.pdf                      1   \n",
            "1  Antenna Product specifications-SLU0638DS.pdf                      1   \n",
            "0                                MT536M49VH.pdf                      1   \n",
            "3                                MT-799012W.pdf                      1   \n",
            "\n",
            "                                       table_content  \n",
            "4                   0               1\\n0       Me...  \n",
            "2                         Electrical Specificatio...  \n",
            "1                                                ...  \n",
            "0                                                ...  \n",
            "3                          0                     ...  \n",
            "\n",
            "--- Step 4a: Generating Clean Context (with gpt-4o-mini)... ---\n",
            "The device features mechanical dimensions of 277 x 277 x 20 mm and weighs 1.8\n",
            "kg. It utilizes a WR-12 connector and has a radome made of polypropylene with an\n",
            "aluminum back plate, ensuring water tightness rated at IP67. The electrical\n",
            "specifications include a frequency range of 24.0 to 26.5 GHz with single\n",
            "polarization (vertical or horizontal). The antenna provides a low gain of 36.5\n",
            "dBi, mid gain of 37.0 dBi, and top gain of 37.5 dBi, with a beam width of 2.4°\n",
            "and a cross-polarization discrimination of 30 dB. The front-to-back ratio is 63\n",
            "dB, and the voltage standing wave ratio (VSWR) is 1.3 with a return loss of 17.7\n",
            "dB. It complies with ETSI EN 302217 Range 4 Class 3 regulations. The operational\n",
            "temperature range is -45 to +60 °C, with a wind velocity survival rating of 252\n",
            "km/h and operational rating of 200 km/h. The device can withstand an ice load of\n",
            "25.4 mm. The packaging dimensions are 480 x 480 x 267 mm, and the net weight is\n",
            "5.9 kg.\n",
            "\n",
            "--- Step 4b: Generating Final Answer (with gpt-4o-mini)... ---\n",
            "\n",
            "==================================================\n",
            "Final Generated Answer (GPT-4o mini)\n",
            "==================================================\n",
            "The weight of the MTI MT-799012/W antenna is 1.8 kg.\n",
            "==================================================\n",
            "\n",
            "Enter your semantic query (or type 'exit' to quit): exit\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# MAIN EXECUTION SCRIPT\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # 1. SET UP YOUR PDF DIRECTORY IN GOOGLE DRIVE\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "        # --- IMPORTANT: CHANGE THIS to the path of your folder in Google Drive ---\n",
        "        PDF_DIRECTORY = '/content/drive/MyDrive/pdf_folder/'\n",
        "        print(f\"Target directory set to: {PDF_DIRECTORY}\")\n",
        "    except (ImportError, ModuleNotFoundError):\n",
        "        # Fallback for local execution if not in Colab\n",
        "        PDF_DIRECTORY = './pdf_database/'\n",
        "\n",
        "    if not os.path.exists(PDF_DIRECTORY):\n",
        "        os.makedirs(PDF_DIRECTORY)\n",
        "        print(f\"\\nCreated directory '{PDF_DIRECTORY}'.\")\n",
        "        print(\"Please upload your PDF files to this folder and run this cell again.\")\n",
        "    else:\n",
        "        # 2. CREATE THE MASTER DATAFRAME\n",
        "        # This step processes all PDFs and can take a while.\n",
        "        master_dataframe = process_pdf_database(PDF_DIRECTORY)\n",
        "\n",
        "        if not master_dataframe.empty:\n",
        "            print(f\"\\nSuccessfully created a master DataFrame with {len(master_dataframe)} text chunks.\")\n",
        "\n",
        "            # Save the master dataframe for future use so you don't have to process again\n",
        "            master_dataframe.to_csv(\"master_database.csv\", index=False)\n",
        "            print(\"\\nSaved the master DataFrame to 'master_database.csv'\")\n",
        "\n",
        "            # 3. CREATE SEMANTIC EMBEDDINGS\n",
        "            embedding_model, document_embeddings = create_embeddings(master_dataframe)\n",
        "\n",
        "            # Optional: Save embeddings for faster loading next time\n",
        "            np.save('document_embeddings.npy', document_embeddings)\n",
        "            print(\"Saved document embeddings to 'document_embeddings.npy'\")\n",
        "\n",
        "            # 4. START THE INTERACTIVE Q&A LOOP\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"System is ready. You can now ask questions.\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "            user_query = input(\"Enter your semantic query (or type 'exit' to quit): \")\n",
        "            while user_query.lower() != 'exit':\n",
        "                if user_query:\n",
        "                    # Step 4a: Retrieve relevant chunks from your documents\n",
        "                    print(\"\\n--- Step 4: Retrieving relevant chunks... ---\")\n",
        "                    top_results = search_documents_semantic(\n",
        "                        user_query,\n",
        "                        embedding_model,\n",
        "                        document_embeddings,\n",
        "                        master_dataframe,\n",
        "                        top_n=5 # You can adjust this number\n",
        "                    )\n",
        "\n",
        "                    print(\"Top Retrieved Chunks (for context):\")\n",
        "                    print(top_results[['pdf_name', 'original_table_number', 'table_content']])\n",
        "\n",
        "                    # Step 4b: Pass the retrieved chunks to the LLM to generate a final answer\n",
        "                    final_answer = generate_final_answer(user_query, top_results)\n",
        "\n",
        "                    # Step 4c: Display the final, polished answer\n",
        "                    print(\"\\n\" + \"=\"*50)\n",
        "                    print(\"Final Generated Answer (GPT-4o mini)\")\n",
        "                    print(\"=\"*50)\n",
        "                    print(textwrap.fill(final_answer, width=80))\n",
        "                    print(\"=\"*50)\n",
        "\n",
        "                user_query = input(\"\\nEnter your semantic query (or type 'exit' to quit): \")\n",
        "        else:\n",
        "            print(\"\\nNo content was extracted from the PDFs. The process cannot continue.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpcBN49Nj9/BWiP2h6DfnZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b28deba4070b4ae7b18c0a545f5d5b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a99af8fbefd45099ac6735f1fb48b37",
              "IPY_MODEL_e0c77736ba2c4eb5aff2afddfe950f6b",
              "IPY_MODEL_a9baaa876a5c4ddb8453ae68f5f41f0f"
            ],
            "layout": "IPY_MODEL_73d54e9ae76a4606a44806ea5ae44982"
          }
        },
        "8a99af8fbefd45099ac6735f1fb48b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdc89286104e437c8ab0e921f70d6685",
            "placeholder": "​",
            "style": "IPY_MODEL_b11342e0c3924078b5cdfef929217c9f",
            "value": "Processing PDFs: 100%"
          }
        },
        "e0c77736ba2c4eb5aff2afddfe950f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9812d33e2fe842909415ea9dd4777848",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_070e3f9def5c419eae6f879abb48e1a0",
            "value": 4
          }
        },
        "a9baaa876a5c4ddb8453ae68f5f41f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f04180e5fce0466ab87199b60b7c9076",
            "placeholder": "​",
            "style": "IPY_MODEL_f8d0e75209d74dfa87eee58048349425",
            "value": " 4/4 [05:57&lt;00:00, 68.17s/it]"
          }
        },
        "73d54e9ae76a4606a44806ea5ae44982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdc89286104e437c8ab0e921f70d6685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b11342e0c3924078b5cdfef929217c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9812d33e2fe842909415ea9dd4777848": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "070e3f9def5c419eae6f879abb48e1a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f04180e5fce0466ab87199b60b7c9076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8d0e75209d74dfa87eee58048349425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87da898d54cc4f36b8647b212a0c9cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d23f9fe295824deea94b87c7a7652751",
              "IPY_MODEL_80c3c48c43294a80bf2040bfa60caeb8",
              "IPY_MODEL_c2f2b1206dbb41b2b8415688dd3a16de"
            ],
            "layout": "IPY_MODEL_affbbcb1cd364002bff01b6e8686beb9"
          }
        },
        "d23f9fe295824deea94b87c7a7652751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e7b7816233c4f9ebcf27d670db26e7b",
            "placeholder": "​",
            "style": "IPY_MODEL_97cee9ab229d42aa85b01626df2e07ee",
            "value": "Batches: 100%"
          }
        },
        "80c3c48c43294a80bf2040bfa60caeb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51f7a867066f4bbdbefd9d0df4b1fa7c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc5b3c9d362b4f2fa46db800460f2ab5",
            "value": 1
          }
        },
        "c2f2b1206dbb41b2b8415688dd3a16de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8f9f0016834464596df37a6ade61951",
            "placeholder": "​",
            "style": "IPY_MODEL_e39a85a4ab9a4b1186dfe626c2c4fd98",
            "value": " 1/1 [00:00&lt;00:00,  1.44it/s]"
          }
        },
        "affbbcb1cd364002bff01b6e8686beb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e7b7816233c4f9ebcf27d670db26e7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97cee9ab229d42aa85b01626df2e07ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51f7a867066f4bbdbefd9d0df4b1fa7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc5b3c9d362b4f2fa46db800460f2ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8f9f0016834464596df37a6ade61951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e39a85a4ab9a4b1186dfe626c2c4fd98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}